import os
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig
import time
import colorama
from colorama import Fore, Style, Back
import sys
import threading
import re
import json
import numpy as np
from collections import deque

# Initialisation des couleurs
colorama.init()

# Configuration - MODIFI√â POUR UTILISER LE MOD√àLE FINE-TUN√â
# Utilisons le chemin absolu pour √©viter les erreurs
MODEL_PATH = os.path.abspath("FineTune/mistral-finetuned")

print(f"Chemin du mod√®le: {MODEL_PATH}")

# Token non n√©cessaire pour un mod√®le local
os.environ["HF_TOKEN"] = ""

# Syst√®me de raisonnement avanc√© - cat√©gories et mots-cl√©s
CATEGORIES = {
    "SALUTATION": ["bonjour", "salut", "bonsoir", "hello", "coucou", "hey", "yo", "wesh"],
    "RECHERCHE_PRODUIT": ["cherche", "trouver", "recherche", "o√π", "produit", "article", "acheter", "vendre", "achat"],
    "COMPTE_UTILISATEUR": ["compte", "inscription", "connecter", "mot de passe", "profil", "identifiant", "connexion"],
    "COMMANDE": ["commande", "commander", "achat", "acheter", "panier", "caddie", "achats"],
    "PAIEMENT": ["payer", "paiement", "carte", "bancaire", "paypal", "prix", "co√ªt", "euros", "‚Ç¨", "tarif"],
    "LIVRAISON": ["livrer", "livraison", "exp√©dition", "d√©lai", "quand", "colis", "recevoir", "envoi"],
    "RETOUR": ["retour", "renvoyer", "rembourser", "remboursement", "annuler", "annulation", "renvoie"],
    "SERVICE_CLIENT": ["probl√®me", "aide", "assister", "contacter", "contact", "service client", "assistance"],
    "PRODUIT_SPECIFIQUE": ["smartphone", "ordinateur", "v√™tement", "meuble", "t√©l√©vision", "chaussure", "√©lectronique"],
    "CONVERSATION": ["comment √ßa va", "qui es-tu", "merci", "au revoir", "bonne journ√©e", "t'es qui", "tu es qui"],
    "INFORMATION_SITE": ["site", "entreprise", "magasin", "boutique", "marketplace", "shop", "web"],
    "FIN_CONVERSATION": ["au revoir", "bye", "√† bient√¥t", "adieu", "termin√©", "fin", "salut", "ciao"],
    "OPINION": ["penses", "crois", "avis", "opinion", "pr√©f√®res", "meilleur", "id√©e", "suggestion"]
}

# Dictionnaire inverse pour le lookup rapide des mots-cl√©s vers cat√©gories
KEYWORD_TO_CATEGORY = {}
for category, keywords in CATEGORIES.items():
    for keyword in keywords:
        if keyword not in KEYWORD_TO_CATEGORY:
            KEYWORD_TO_CATEGORY[keyword] = []
        KEYWORD_TO_CATEGORY[keyword].append(category)

# Mod√®les de r√©ponse pour assurer la coh√©rence
RESPONSE_TEMPLATES = {
    "SALUTATION": [
        "Bonjour ! Comment puis-je vous aider avec vos achats aujourd'hui ?",
        "Salut ! Ravi de vous parler. Que puis-je faire pour vous ?",
        "Bonjour ! Je suis l√† pour r√©pondre √† vos questions sur notre site e-commerce."
    ],
    "FIN_CONVERSATION": [
        "Au revoir ! N'h√©sitez pas √† revenir si vous avez d'autres questions.",
        "√Ä bient√¥t ! Votre panier sera sauvegard√© pour votre prochaine visite.",
        "Merci de votre visite ! J'esp√®re avoir pu vous aider aujourd'hui."
    ]
}

# Empreintes vectorielles simplifi√©es pour certains th√®mes
THEME_VECTORS = {
    "produit": np.array([1.0, 0.2, 0.1, 0.3, 0.0]),
    "paiement": np.array([0.2, 1.0, 0.3, 0.1, 0.0]),
    "livraison": np.array([0.1, 0.3, 1.0, 0.2, 0.0]),
    "compte": np.array([0.3, 0.1, 0.2, 1.0, 0.0]),
    "conversation": np.array([0.0, 0.0, 0.0, 0.0, 1.0])
}


class AdvancedReasoningSystem:
    def __init__(self):
        # Historique complet de la conversation
        self.conversation_history = []

        # File d'attente pour le contexte imm√©diat (derniers √©changes)
        self.recent_context = deque(maxlen=5)

        # Donn√©es utilisateur persistantes
        self.user_data = {
            "interests": set(),  # Centre d'int√©r√™ts
            "products_viewed": set(),  # Produits consult√©s
            "issues": set(),  # Probl√®mes rencontr√©s
            "sentiment": "neutral",  # Sentiment g√©n√©ral
            "name": None,  # Nom si mentionn√©
            "conversation_topics": {}  # Fr√©quence des sujets abord√©s
        }

        # √âtat actuel de la conversation
        self.current_state = {
            "topic": None,
            "subtopic": None,
            "needs_clarification": False,
            "expected_response_type": None,
            "topic_vector": np.zeros(5)  # Repr√©sentation vectorielle du th√®me actuel
        }

        # M√©canisme d'auto-correction
        self.correction_history = []

        # Log des raisonnements
        self.reasoning_log = []

    def add_to_history(self, user_input, response):
        """Ajoute un √©change √† l'historique et met √† jour le contexte r√©cent"""
        exchange = {"user": user_input, "assistant": response, "timestamp": time.time()}
        self.conversation_history.append(exchange)
        self.recent_context.append(exchange)

        # Mettre √† jour les donn√©es utilisateur
        self._update_user_data(user_input)

        # Mettre √† jour le vecteur de th√®me actuel
        self._update_topic_vector(user_input)

    def _update_user_data(self, text):
        """Mise √† jour des donn√©es utilisateur bas√©es sur le texte"""
        text_lower = text.lower()

        # D√©tection d'int√©r√™ts
        for category, keywords in CATEGORIES.items():
            if category in ["PRODUIT_SPECIFIQUE", "RECHERCHE_PRODUIT"]:
                for keyword in keywords:
                    if keyword in text_lower:
                        self.user_data["interests"].add(keyword)

        # Comptage des sujets de conversation
        category = self.categorize_query(text)
        if category in self.user_data["conversation_topics"]:
            self.user_data["conversation_topics"][category] += 1
        else:
            self.user_data["conversation_topics"][category] = 1

        # Analyse de sentiment basique
        positive_words = ["merci", "super", "g√©nial", "content", "satisfait", "excellent"]
        negative_words = ["probl√®me", "erreur", "insatisfait", "d√©√ßu", "mauvais", "difficile"]

        pos_count = sum(1 for word in positive_words if word in text_lower)
        neg_count = sum(1 for word in negative_words if word in text_lower)

        if pos_count > neg_count:
            self.user_data["sentiment"] = "positive"
        elif neg_count > pos_count:
            self.user_data["sentiment"] = "negative"

    def _update_topic_vector(self, text):
        """Met √† jour le vecteur repr√©sentant le th√®me actuel de la conversation"""
        text_lower = text.lower()

        # R√©initialiser l√©g√®rement le vecteur pour permettre l'√©volution du th√®me
        self.current_state["topic_vector"] *= 0.8

        # Ajouter la contribution du message actuel
        for theme, vector in THEME_VECTORS.items():
            if any(keyword in text_lower for keyword in CATEGORIES.get(theme.upper(), [])):
                self.current_state["topic_vector"] += 0.5 * vector

        # Normaliser le vecteur
        norm = np.linalg.norm(self.current_state["topic_vector"])
        if norm > 0:
            self.current_state["topic_vector"] /= norm

    def categorize_query(self, query):
        """Version am√©lior√©e de la cat√©gorisation des requ√™tes"""
        query_lower = query.lower()

        # Comptage des mots-cl√©s par cat√©gorie
        category_scores = {}

        # Analyse bas√©e sur les mots-cl√©s
        for word in query_lower.split():
            if word in KEYWORD_TO_CATEGORY:
                for category in KEYWORD_TO_CATEGORY[word]:
                    category_scores[category] = category_scores.get(category, 0) + 1

        # Analyse bas√©e sur des expressions plus longues
        for category, keywords in CATEGORIES.items():
            for keyword in keywords:
                if len(keyword.split()) > 1 and keyword in query_lower:
                    category_scores[category] = category_scores.get(category,
                                                                    0) + 2  # Poids plus √©lev√© pour les expressions

        # Si c'est une question explicite
        if "?" in query and not category_scores:
            # D√©tecter le type de question bas√© sur les mots interrogatifs
            question_words = ["comment", "pourquoi", "quand", "o√π", "qui", "quoi", "quel", "quelle", "quels", "quelles"]
            for word in question_words:
                if word in query_lower:
                    if any(k in query_lower for k in CATEGORIES["RECHERCHE_PRODUIT"]):
                        category_scores["RECHERCHE_PRODUIT"] = category_scores.get("RECHERCHE_PRODUIT", 0) + 1
                    elif any(k in query_lower for k in CATEGORIES["LIVRAISON"]):
                        category_scores["LIVRAISON"] = category_scores.get("LIVRAISON", 0) + 1
                    elif any(k in query_lower for k in CATEGORIES["PAIEMENT"]):
                        category_scores["PAIEMENT"] = category_scores.get("PAIEMENT", 0) + 1
                    break

        # V√©rifier la proximit√© vectorielle avec le th√®me pr√©c√©dent pour la continuit√©
        prev_category = self.current_state.get("topic")
        if prev_category and prev_category in category_scores:
            # Bonus pour maintenir la coh√©rence th√©matique
            category_scores[prev_category] += 0.5

        # Si aucune cat√©gorie n'est identifi√©e ou que le score est faible
        if not category_scores or max(category_scores.values(), default=0) < 0.7:
            # V√©rifier s'il s'agit d'une salutation ou d'une fin de conversation
            if any(word in query_lower for word in CATEGORIES["SALUTATION"]) and len(query_lower) < 20:
                return "SALUTATION"
            elif any(word in query_lower for word in CATEGORIES["FIN_CONVERSATION"]) and len(query_lower) < 20:
                return "FIN_CONVERSATION"
            else:
                # Continuit√© par d√©faut ou conversation g√©n√©rale
                return "CONVERSATION"

        # Retourner la cat√©gorie avec le score le plus √©lev√©
        return max(category_scores, key=category_scores.get)

    def extract_key_entities(self, query):
        """Extrait les entit√©s cl√©s de la requ√™te"""
        entities = {
            "products": [],
            "actions": [],
            "concerns": [],
            "locations": [],
            "time_references": []
        }

        query_lower = query.lower()

        # Extraction de produits
        for product in CATEGORIES["PRODUIT_SPECIFIQUE"]:
            if product in query_lower:
                entities["products"].append(product)

        # Extraction d'actions
        action_words = ["acheter", "commander", "trouver", "chercher", "payer", "annuler", "retourner", "√©changer"]
        for action in action_words:
            if action in query_lower:
                entities["actions"].append(action)

        # Extraction de pr√©occupations
        concern_words = ["probl√®me", "d√©faut", "retard", "erreur", "question", "inqui√©tude", "livraison", "d√©lai"]
        for concern in concern_words:
            if concern in query_lower:
                entities["concerns"].append(concern)

        # Extraction simple de r√©f√©rences temporelles
        time_refs = ["aujourd'hui", "demain", "bient√¥t", "maintenant", "apr√®s", "avant", "d√©lai", "attendre"]
        for time_ref in time_refs:
            if time_ref in query_lower:
                entities["time_references"].append(time_ref)

        return entities

    def analyze_context_relevance(self, query, category):
        """Analyse la pertinence du contexte r√©cent pour la requ√™te actuelle"""
        if not self.recent_context:
            return {
                "relevance": "no_context",
                "continuity": 0.0,
                "reference_to_previous": False
            }

        query_lower = query.lower()

        # V√©rifier les r√©f√©rences explicites aux messages pr√©c√©dents
        reference_words = ["tu as dit", "tu mentionnais", "comme tu disais", "pr√©c√©demment", "avant", "tu parlais"]
        explicit_reference = any(ref in query_lower for ref in reference_words)

        # V√©rifier la continuit√© th√©matique
        last_exchange = self.recent_context[-1]
        last_category = self.categorize_query(last_exchange["user"])

        # Calcul de similarit√© bas√© sur les cat√©gories
        category_continuity = 1.0 if category == last_category else 0.0

        # Calcul de similarit√© bas√© sur les mots partag√©s (simple)
        last_words = set(last_exchange["user"].lower().split())
        current_words = set(query_lower.split())
        word_overlap = len(last_words.intersection(current_words)) / max(1, len(current_words))

        # Combinaison des scores
        continuity_score = 0.7 * category_continuity + 0.3 * word_overlap

        if explicit_reference:
            return {
                "relevance": "explicit_reference",
                "continuity": continuity_score,
                "reference_to_previous": True
            }
        elif continuity_score > 0.3:
            return {
                "relevance": "thematic_continuity",
                "continuity": continuity_score,
                "reference_to_previous": False
            }
        else:
            return {
                "relevance": "new_topic",
                "continuity": continuity_score,
                "reference_to_previous": False
            }

    def determine_response_approach(self, query, category, entities, context_analysis):
        """D√©termine l'approche de r√©ponse en fonction de l'analyse"""
        approach = {
            "tone": "neutral",
            "format": "standard",
            "focus": category.lower(),
            "needs_clarification": False,
            "should_verify_understanding": False
        }

        # Ajustement du ton en fonction du sentiment utilisateur
        if self.user_data["sentiment"] == "positive":
            approach["tone"] = "friendly"
        elif self.user_data["sentiment"] == "negative":
            approach["tone"] = "helpful"

        # Ajustement du format en fonction de la requ√™te
        if category == "RECHERCHE_PRODUIT" and len(entities["products"]) == 0:
            approach["needs_clarification"] = True
            approach["format"] = "question"
        elif category == "OPINION":
            approach["format"] = "balanced"
        elif category in ["LIVRAISON", "PAIEMENT", "RETOUR"]:
            approach["format"] = "informative"

        # Ajustement si r√©f√©rence au contexte pr√©c√©dent
        if context_analysis["reference_to_previous"]:
            approach["should_verify_understanding"] = True

        # Ajout de structure pour les questions complexes
        query_words = query.lower().split()
        if len(query_words) > 10 and "?" in query:
            approach["format"] = "structured"

        return approach

    def detect_offensive_content(self, text):
        """
        D√©tecte le contenu offensant ou inappropri√© dans le texte utilisateur.
        Retourne un dictionnaire avec les r√©sultats de l'analyse.
        """
        text_lower = text.lower()

        # Liste de mots et expressions offensants
        # Cette liste peut √™tre √©tendue selon les besoins
        offensive_words = [
            # Insultes directes
            "connard", "connasse", "con", "salope", "pute", "putain", "encul√©", "encule",
            "fils de pute", "ta gueule", "ta m√®re", "va te faire", "ntm", "fdp", "pd", "tg",
            "nique", "niquer", "bite", "couilles", "merde", "cr√©tin", "d√©bile", "abruti",

            # Expressions d√©sobligeantes
            "ferme la", "ta race", "sale", "d√©gueulasse", "idiot", "imb√©cile", "b√¢tard",

            # Discriminations
            "negro", "n√©gro", "n√®gre", "bougnoule", "p√©d√©", "pd", "gouine", "travelo",
            "tantouze", "tapette", "transsexuel", "sale juif", "sale arabe", "sale noir",

            # Menaces
            "je vais te", "je te tue", "je te retrouve", "je vais te retrouver",

            # Expressions grossi√®res
            "va chier", "va te faire foutre", "mange tes morts", "suce ma"
        ]

        # D√©tection pr√©cise pour √©viter les faux positifs
        # Par exemple, "constitution" contient "con" mais n'est pas offensant
        detected_words = []
        for word in offensive_words:
            # Si le mot offensant est entour√© d'espaces ou de ponctuation
            pattern = r'(\s|^|[,.!?;:\'\"]){0}(\s|$|[,.!?;:\'\"])'.format(word)
            if re.search(pattern, text_lower, re.IGNORECASE) or word in text_lower.split():
                detected_words.append(word)

        # Analyse du niveau d'hostilit√©
        hostility_level = 0
        if detected_words:
            # Plus il y a de mots offensants, plus le niveau d'hostilit√© est √©lev√©
            hostility_level = min(1.0, len(detected_words) * 0.2)  # Plafonn√© √† 1.0

            # Certains mots indiquent une hostilit√© plus √©lev√©e
            high_hostility_words = ["fils de pute", "je te tue", "je vais te retrouver", "nique"]
            if any(word in detected_words for word in high_hostility_words):
                hostility_level = 1.0

        # Analyse d'autres signes d'hostilit√© (majuscules excessives, ponctuation excessive)
        caps_ratio = sum(1 for c in text if c.isupper()) / max(1, len(text))
        if caps_ratio > 0.5 and len(text) > 5:  # Si plus de 50% en majuscules
            hostility_level += 0.2

        exclamation_count = text.count('!')
        if exclamation_count > 3:  # Beaucoup de points d'exclamation indiquent de l'agressivit√©
            hostility_level += 0.1

        # Plafonner √† 1.0
        hostility_level = min(1.0, hostility_level)

        # Classification du contenu offensant
        offensive_type = None
        if detected_words:
            if any(word in ["connard", "con", "abruti", "d√©bile", "idiot"] for word in detected_words):
                offensive_type = "insulte_intelligence"
            elif any(word in ["salope", "pute", "putain", "encul√©"] for word in detected_words):
                offensive_type = "insulte_sexuelle"
            elif any(word in ["negro", "n√©gro", "n√®gre", "bougnoule", "sale juif", "sale arabe"] for word in
                     detected_words):
                offensive_type = "discrimination_raciale"
            elif any(word in ["je vais te", "je te tue", "je te retrouve"] for word in detected_words):
                offensive_type = "menace"
            else:
                offensive_type = "insulte_g√©n√©rale"

        result = {
            "is_offensive": len(detected_words) > 0,
            "offensive_words": detected_words,
            "hostility_level": hostility_level,
            "offensive_type": offensive_type,
            "caps_ratio": caps_ratio,
            "exclamation_count": exclamation_count
        }

        return result

    def determine_response_to_offensive_content(self, offensive_analysis):
        """
        D√©termine la r√©ponse appropri√©e au contenu offensant.
        """
        if not offensive_analysis["is_offensive"]:
            return None

        hostility = offensive_analysis["hostility_level"]
        offensive_type = offensive_analysis["offensive_type"]

        if hostility > 0.8:
            # Contenu tr√®s offensant - r√©ponse ferme mais professionnelle
            return {
                "response_type": "firm_boundary",
                "message": "Je ne peux pas continuer cette conversation avec ce type de langage. Je suis l√† pour vous aider de mani√®re respectueuse. Si vous souhaitez poursuivre, merci d'utiliser un langage appropri√©."
            }
        elif hostility > 0.5:
            # Contenu mod√©r√©ment offensant - rappel des r√®gles
            return {
                "response_type": "polite_reminder",
                "message": "Je vous invite √† utiliser un langage plus respectueux pour que je puisse vous aider efficacement. Comment puis-je vous assister aujourd'hui ?"
            }
        else:
            # Contenu l√©g√®rement offensant - r√©orientation positive
            return {
                "response_type": "redirection",
                "message": "Je suis l√† pour vous aider. Comment puis-je vous √™tre utile concernant notre site e-commerce ?"
            }

    def verify_response_consistency(self, query, proposed_response, category):
        """V√©rifie que la r√©ponse est coh√©rente avec la requ√™te et la cat√©gorie"""
        consistency = {
            "is_consistent": True,
            "issues": [],
            "suggestions": []
        }

        # V√©rification de coh√©rence basique
        if category == "SALUTATION" and len(proposed_response) > 200:
            consistency["is_consistent"] = False
            consistency["issues"].append("La r√©ponse √† une salutation est trop longue")
            consistency["suggestions"].append("R√©duire la r√©ponse √† une salutation simple")

        # V√©rification de pr√©sence de contenu non demand√©
        if category == "SALUTATION" and any(
                keyword in proposed_response.lower() for keyword in ["cadeau", "promotion", "offre"]):
            consistency["is_consistent"] = False
            consistency["issues"].append("La r√©ponse contient des informations non demand√©es")
            consistency["suggestions"].append("Se limiter √† une salutation cordiale")

        # V√©rification de correspondance √† la question
        if "?" in query:
            # V√©rifier si la r√©ponse contient des informations pertinentes
            question_topic = "inconnu"
            for cat, keywords in CATEGORIES.items():
                if any(keyword in query.lower() for keyword in keywords):
                    question_topic = cat.lower()
                    break

            # V√©rifie si la r√©ponse aborde bien le sujet de la question
            if question_topic != "inconnu" and not any(
                    keyword in proposed_response.lower() for keyword in CATEGORIES.get(question_topic.upper(), [])):
                consistency["is_consistent"] = False
                consistency["issues"].append(
                    f"La r√©ponse ne semble pas aborder le sujet de la question ({question_topic})")
                consistency["suggestions"].append(f"Inclure des informations sur {question_topic}")

        return consistency

    def format_reasoning_for_prompt(self, query):
        """G√©n√®re un raisonnement structur√© pour guider la g√©n√©ration de r√©ponse"""
        # 1. Cat√©gorisation
        category = self.categorize_query(query)

        # 2. Extraction d'entit√©s
        entities = self.extract_key_entities(query)

        # 3. Analyse du contexte
        context_analysis = self.analyze_context_relevance(query, category)

        # 4. D√©termination de l'approche
        approach = self.determine_response_approach(query, category, entities, context_analysis)

        # Construction du raisonnement structur√©
        reasoning_steps = [
            f"1. CAT√âGORISATION: Cette question appartient √† la cat√©gorie {category}.",
            f"2. CONTEXTE: {context_analysis['relevance'].replace('_', ' ').title()}. "
            f"Niveau de continuit√© avec l'√©change pr√©c√©dent: {context_analysis['continuity']:.1f}/1.0.",
            f"3. ENTIT√âS D√âTECT√âES:"
        ]

        # Ajouter les entit√©s d√©tect√©es
        for entity_type, entity_values in entities.items():
            if entity_values:
                reasoning_steps.append(f"   - {entity_type.capitalize()}: {', '.join(entity_values)}")

        # Ajouter l'approche de r√©ponse
        reasoning_steps.append(f"4. APPROCHE DE R√âPONSE:")
        reasoning_steps.append(f"   - Ton: {approach['tone']}")
        reasoning_steps.append(f"   - Format: {approach['format']}")
        reasoning_steps.append(f"   - Focus: {approach['focus']}")

        if approach['needs_clarification']:
            reasoning_steps.append(f"   - BESOIN DE CLARIFICATION: Oui")

        # Ajouter le contexte utilisateur pertinent
        reasoning_steps.append(f"5. CONTEXTE UTILISATEUR:")
        if self.user_data["interests"]:
            reasoning_steps.append(f"   - Int√©r√™ts d√©tect√©s: {', '.join(self.user_data['interests'])}")
        reasoning_steps.append(f"   - Sentiment utilisateur: {self.user_data['sentiment']}")

        # Ajouter des recommandations sp√©cifiques
        reasoning_steps.append(f"6. RECOMMANDATIONS:")

        if category == "SALUTATION":
            reasoning_steps.append(f"   - Garder la r√©ponse br√®ve et accueillante")
            reasoning_steps.append(f"   - Ne pas introduire de sujets non sollicit√©s")
        elif category == "RECHERCHE_PRODUIT":
            if not entities["products"]:
                reasoning_steps.append(f"   - Demander plus de pr√©cisions sur le type de produit recherch√©")
            else:
                reasoning_steps.append(f"   - Fournir des informations sur {', '.join(entities['products'])}")

        # Ajouter des contraintes anti-hallucination pour les cas sp√©cifiques
        if category == "SALUTATION":
            reasoning_steps.append(f"7. CONTRAINTES:")
            reasoning_steps.append(f"   - Ne pas inventer de besoins ou de questions de l'utilisateur")
            reasoning_steps.append(f"   - Se limiter √† une salutation et une offre d'aide g√©n√©rale")
            reasoning_steps.append(f"   - Ne pas supposer ce que l'utilisateur veut sans qu'il l'ait mentionn√©")

        # Stocker le raisonnement dans le log
        reasoning_dict = {
            "timestamp": time.time(),
            "query": query,
            "category": category,
            "context_analysis": context_analysis,
            "entities": entities,
            "approach": approach,
            "reasoning_steps": reasoning_steps
        }
        self.reasoning_log.append(reasoning_dict)

        return "\n".join(reasoning_steps), category, approach


def print_slowly(text, delay=0.001):
    """Affiche le texte caract√®re par caract√®re pour simuler une r√©ponse en temps r√©el"""
    for char in text:
        print(char, end='', flush=True)
        # Pause plus longue apr√®s les sauts de ligne pour un effet plus naturel
        if char == '\n':
            time.sleep(delay * 5)  # Pause plus longue pour les sauts de ligne
        else:
            time.sleep(delay)
    print()  # Saut de ligne final


def format_response_text(text):
    """Am√©liore le formatage du texte pour qu'il soit plus lisible"""

    # Si le texte est court ou contient d√©j√† des sauts de ligne, on le retourne tel quel
    if len(text) < 100 or '\n' in text:
        return text

    # Sinon, on ajoute des sauts de ligne pour am√©liorer la lisibilit√©
    formatted_text = ""
    buffer = ""

    # Ajoute un saut de ligne apr√®s chaque phrase
    for i, char in enumerate(text):
        buffer += char

        # D√©tecte la fin d'une phrase (point, point d'exclamation ou d'interrogation
        # suivi d'un espace ou en fin de texte)
        if char in ['.', '!', '?'] and (i + 1 < len(text) and text[i + 1] == ' ' or i + 1 == len(text)):
            formatted_text += buffer
            buffer = ""
            if i + 1 < len(text):  # S'assurer qu'on n'est pas √† la fin du texte
                formatted_text += "\n\n"  # Ajouter un double saut de ligne entre les phrases

    # Ajouter ce qui reste dans le buffer
    formatted_text += buffer

    return formatted_text


def print_header():
    """Affiche l'en-t√™te de l'interface de chat"""
    os.system('cls' if os.name == 'nt' else 'clear')  # Efface l'√©cran
    print(f"{Back.BLUE}{Fore.WHITE} MON POTE MISTRAL - SYST√àME DE RAISONNEMENT AVANC√â {Style.RESET_ALL}")
    print(f"{Fore.CYAN}{'=' * 80}{Style.RESET_ALL}")
    print(f"{Fore.YELLOW}Mod√®le: {MODEL_PATH}{Style.RESET_ALL}")
    print(f"{Fore.YELLOW}GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}{Style.RESET_ALL}")
    print(f"{Fore.CYAN}{'=' * 80}{Style.RESET_ALL}\n")


# Fonction d'animation pendant la g√©n√©ration
def thinking_animation(stop_event):
    """Animation √† afficher pendant que le mod√®le g√©n√®re une r√©ponse"""
    animations = [
        "üß† ‚öôÔ∏è ... ",
        "üß†  ‚öôÔ∏è... ",
        "üß†   ‚öôÔ∏è.. ",
        "üß†    ‚öôÔ∏è. ",
        "üß†     ‚öôÔ∏è ",
        "üß†    ‚öôÔ∏è. ",
        "üß†   ‚öôÔ∏è.. ",
        "üß†  ‚öôÔ∏è... ",
    ]
    i = 0
    while not stop_event.is_set():
        print(f"\r{Fore.YELLOW}Ton pote r√©fl√©chit {animations[i]}{Style.RESET_ALL}", end="", flush=True)
        i = (i + 1) % len(animations)
        time.sleep(0.1)
    # Nettoyer la ligne une fois termin√©
    print("\r" + " " * 50, end="\r")


def correct_response_if_needed(reasoning_system, query, response, category, approach):
    """Corrige la r√©ponse si elle n'est pas coh√©rente avec la demande"""
    # Pour les salutations, v√©rifier que la r√©ponse est simple et appropri√©e
    if category == "SALUTATION" and len(response) > 200:
        # La r√©ponse √† une salutation est trop longue, on la remplace
        corrected = "Bonjour ! Je suis l√† pour vous aider avec vos questions sur notre site e-commerce. Comment puis-je vous √™tre utile aujourd'hui ?"
        print(f"{Fore.RED}[Correction auto: R√©ponse simplifi√©e pour salutation]{Style.RESET_ALL}")
        return corrected

    # V√©rifier si la r√©ponse contient des informations non sollicit√©es pour une salutation
    if category == "SALUTATION" and ("cadeau" in response.lower() or "no√´l" in response.lower()):
        # La r√©ponse contient des informations non sollicit√©es
        corrected = "Bonjour ! Je suis ravi de vous accueillir. Comment puis-je vous aider aujourd'hui ?"
        print(f"{Fore.RED}[Correction auto: Suppression de contenu non sollicit√©]{Style.RESET_ALL}")
        return corrected

    return response


def main():
    # Initialisation du syst√®me de raisonnement avanc√©
    reasoning_system = AdvancedReasoningSystem()

    # Mode debug pour afficher le raisonnement
    debug_mode = False

    # V√©rification de la disponibilit√© du GPU
    if torch.cuda.is_available():
        print(f"{Fore.GREEN}GPU disponible: {torch.cuda.get_device_name(0)}{Style.RESET_ALL}")
    else:
        print(f"{Fore.RED}Pas de GPU disponible, utilisation du CPU{Style.RESET_ALL}")

    print(f"{Fore.YELLOW}Chargement du mod√®le personnalis√© depuis {MODEL_PATH}...{Style.RESET_ALL}")

    # Configuration pour la quantification 8-bit
    quantization_config = BitsAndBytesConfig(
        load_in_8bit=True,
        llm_int8_enable_fp32_cpu_offload=True
    )

    # Chargement du tokenizer - Mod√®le local, pas besoin de token
    tokenizer = AutoTokenizer.from_pretrained(
        MODEL_PATH,
        local_files_only=True  # Indique explicitement d'utiliser uniquement les fichiers locaux
    )

    # Options pour optimiser pour une 3080 (environ 10GB VRAM)
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
        device_map="auto",
        torch_dtype=torch.float16,  # Utilisation de la pr√©cision mixte
        quantization_config=quantization_config,
        local_files_only=True  # Indique explicitement d'utiliser uniquement les fichiers locaux
    )

    # Cr√©er le pipeline de g√©n√©ration de texte - SANS sp√©cifier device
    pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=512,
        do_sample=True,
        temperature=0.7,
        top_p=0.95,
        pad_token_id=tokenizer.eos_token_id  # √âvite le message de warning
    )

    # Interface de chat am√©lior√©e
    chat_history = []

    # Affichage de l'interface
    print_header()
    print(
        f"{Fore.WHITE}Tapez {Fore.GREEN}'aide'{Fore.WHITE} pour les commandes ou {Fore.RED}'quitter'{Fore.WHITE} pour terminer.{Style.RESET_ALL}\n")
    print(f"{Fore.CYAN}Essayez de lui parler de fa√ßon amicale pour voir sa nouvelle personnalit√©!{Style.RESET_ALL}\n")

    while True:
        # Interface utilisateur avec indicateur visuel
        try:
            print(f"{Fore.CYAN}Vous:{Style.RESET_ALL} ", end='', flush=True)
            user_input = input()

            offensive_analysis = reasoning_system.detect_offensive_content(user_input)
            if offensive_analysis["is_offensive"]:
                if debug_mode:
                    print(f"\n{Fore.RED}Contenu offensant d√©tect√©:{Style.RESET_ALL}")
                    print(
                        f"{Fore.RED}Mots d√©tect√©s: {', '.join(offensive_analysis['offensive_words'])}{Style.RESET_ALL}")
                    print(
                        f"{Fore.RED}Niveau d'hostilit√©: {offensive_analysis['hostility_level']:.2f}/1.0{Style.RESET_ALL}")
                    print(f"{Fore.RED}Type d'offense: {offensive_analysis['offensive_type']}{Style.RESET_ALL}\n")

                # D√©terminer la r√©ponse appropri√©e
                offensive_response = reasoning_system.determine_response_to_offensive_content(offensive_analysis)

                # Afficher la r√©ponse pr√©programm√©e au lieu de g√©n√©rer
                print(f"\n{Fore.GREEN}Ton pote:{Style.RESET_ALL}")
                print_slowly(offensive_response["message"])
                print(f"\n{Fore.BLUE}[R√©ponse automatique √† un contenu inappropri√©]{Style.RESET_ALL}\n")

                # Mettre √† jour l'historique avec cette interaction
                chat_history.append((user_input, offensive_response["message"]))
                reasoning_system.add_to_history(user_input, offensive_response["message"])

                # Passer au message suivant
                continue

            # Validation d'entr√©e - s'assurer que l'entr√©e n'est pas vide
            if not user_input.strip():
                print(f"{Fore.YELLOW}Veuillez entrer un message non vide.{Style.RESET_ALL}")
                continue

            # Commandes sp√©ciales
            if user_input.lower() in ["quitter", "exit", "bye"]:
                print(f"\n{Fore.YELLOW}Au revoir mon pote!{Style.RESET_ALL}")
                break
            elif user_input.lower() in ["aide", "help"]:
                print(f"\n{Fore.GREEN}Commandes disponibles:{Style.RESET_ALL}")
                print(f"{Fore.YELLOW}- quitter:{Style.RESET_ALL} Termine la conversation")
                print(f"{Fore.YELLOW}- aide:{Style.RESET_ALL} Affiche cette aide")
                print(f"{Fore.YELLOW}- effacer:{Style.RESET_ALL} Efface l'historique de conversation")
                print(f"{Fore.YELLOW}- reload:{Style.RESET_ALL} Recharge l'interface")
                print(
                    f"{Fore.YELLOW}- debug:{Style.RESET_ALL} Active/d√©sactive le mode debug (affiche le raisonnement)")
                print(f"{Fore.YELLOW}- debug+:{Style.RESET_ALL} Mode debug avec d√©tails avanc√©s")
                continue
            elif user_input.lower() == "effacer":
                chat_history = []
                reasoning_system = AdvancedReasoningSystem()  # R√©initialise le syst√®me de raisonnement
                print(f"\n{Fore.GREEN}Historique de conversation effac√©.{Style.RESET_ALL}")
                continue
            elif user_input.lower() == "reload":
                print_header()
                continue
            elif user_input.lower() == "debug":
                debug_mode = not debug_mode
                print(f"\n{Fore.GREEN}Mode debug {'activ√©' if debug_mode else 'd√©sactiv√©'}.{Style.RESET_ALL}")
                continue
            elif user_input.lower() == "debug+":
                debug_mode = True
                print(f"\n{Fore.GREEN}Mode debug avanc√© activ√©.{Style.RESET_ALL}")
                continue

            # Appliquer le syst√®me de raisonnement avanc√©
            reasoning, category, approach = reasoning_system.format_reasoning_for_prompt(user_input)

            # Afficher le raisonnement en mode debug
            if debug_mode:
                print(f"\n{Fore.MAGENTA}{'=' * 40} ANALYSE {'=' * 40}{Style.RESET_ALL}")
                print(f"{Fore.MAGENTA}{reasoning}{Style.RESET_ALL}")
                print(f"{Fore.MAGENTA}{'=' * 87}{Style.RESET_ALL}\n")

            # Format d'instruction Mistral pour le mod√®le fine-tun√©
            # On inclut le raisonnement dans le prompt pour guider la g√©n√©ration
            prompt = f"<s>[INST] "

            if debug_mode:
                prompt += f"Analyse:\n{reasoning}\n\n"
                # Ajouter des instructions sp√©cifiques bas√©es sur la cat√©gorie
                if category == "SALUTATION":
                    prompt += "IMPORTANT: Reste simple et concis pour cette salutation. Ne suppose pas ce que l'utilisateur veut sans qu'il l'ait mentionn√©. Ne parle pas de cadeaux ou d'achats si l'utilisateur n'en a pas parl√©.\n\n"

            prompt += f"{user_input} [/INST]"

            # Animation de chargement avec un thread s√©par√©
            stop_animation = threading.Event()
            animation_thread = threading.Thread(target=thinking_animation, args=(stop_animation,))
            animation_thread.daemon = True
            animation_thread.start()

            try:
                # G√©n√©rer la r√©ponse
                start_time = time.time()
                response = pipe(prompt, return_full_text=False)[0]["generated_text"]
                gen_time = time.time() - start_time

                # V√©rifier et corriger la r√©ponse si n√©cessaire
                response = correct_response_if_needed(reasoning_system, user_input, response, category, approach)

                # Formater la r√©ponse pour une meilleure lisibilit√©
                response = format_response_text(response)

                # Arr√™ter l'animation
                stop_animation.set()
                animation_thread.join()

                # Afficher la r√©ponse avec mise en forme
                print(f"\n{Fore.GREEN}Ton pote:{Style.RESET_ALL}")

                # Simuler une r√©ponse en temps r√©el (comme un vrai chat)
                # Si la r√©ponse est longue, afficher plus rapidement
                delay = 0.0005 if len(response) > 500 else 0.001  # D√©lais tr√®s courts
                print_slowly(response)

                # Petit indicateur de temps de g√©n√©ration
                print(f"\n{Fore.BLUE}[G√©n√©r√© en {gen_time:.2f}s]{Style.RESET_ALL}\n")

                # Mettre √† jour l'historique de conversation
                chat_history.append((user_input, response))
                reasoning_system.add_to_history(user_input, response)

            except Exception as e:
                # Arr√™ter l'animation en cas d'erreur
                stop_animation.set()
                animation_thread.join()
                print(f"\n{Fore.RED}Erreur: {str(e)}{Style.RESET_ALL}\n")

        except KeyboardInterrupt:
            print(
                f"\n\n{Fore.YELLOW}Session interrompue. Tapez 'quitter' pour sortir ou continuez votre message.{Style.RESET_ALL}\n")
            continue

    # Nettoyage √† la sortie
    colorama.deinit()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print(f"\n\n{Fore.YELLOW}Session termin√©e par l'utilisateur.{Style.RESET_ALL}")
        colorama.deinit()
        sys.exit(0)
